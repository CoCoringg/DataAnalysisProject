{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import tweepy\n",
    "from konlpy.tag import Okt, Mecab\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "import nltk\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_dir = os.getcwd()\n",
    "genre_df = pd.read_csv(current_dir + '/data/genre_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 설정\n",
    "SW = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['고양이', '나', '녜']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = Mecab() \n",
    "tagger.nouns(\"고양이가 냐 하고 울면 나는 녜 하고 울어야지\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kor_preprocessing(text):\n",
    "    tokenizer = Mecab()\n",
    "    total_tokens = tokenizer.nouns(text)\n",
    "    total_tokens = [token for token in total_tokens if len(token) > 1] # token not in SW and \n",
    "    \n",
    "    return total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['액션', '영화']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = list(genre_df['script'])\n",
    "kor_tokens = [kor_preprocessing(doc) for doc in contents]\n",
    "kor_total_tokens = []\n",
    "for L in kor_tokens:\n",
    "    kor_total_tokens += L\n",
    " \n",
    "kor_total_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "europe_genre_keywords = [\"그리스\", \"네덜란드\", \"노르웨이\", \"덴마크\", \"독일\", \"라트비아\", \"루마니아\", \"룩셈부르크\", \"리투아니아\", \"리히텐슈타인\", \"모나코\", \"몬테네그로\", \"몰도바\", \"몰타\", \"벨기에\", \"벨라루스\", \"보스니아-헤르체고비나\", \"북마케도니아\", \"불가리아\", \"사이프러스\", '산마리노', \"세르비아\", \"스웨덴\", \"스위스\", \"스페인\", \"슬로바키아\", \"슬로베니아\", \"아르메니아\", \"아이슬란드\", \"아일랜드\", \"아제르바이잔\", \"안도라\", \"알바니아\", \"에스토니아\", \"영국\", \"오스트리아\", \"우크라이나\" , \"이탈리아\", \"조지아\", \"체코\", \"코소보\", \"크로아티아\", \"터키\", \"포르투갈\", \"폴란드\", \"프랑스\", \"핀란드\", \"헝가리\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e610d3460abe1c45b5b6f2abe26054bb6c069786b46a9661b88c1d9177e6eb4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('corona': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
